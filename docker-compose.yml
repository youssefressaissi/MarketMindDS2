# --- Base service definition ---
x-base_service: &base_service
    volumes:
      - &v1 ./data:/data         # Shared mount for models, configs etc.
      - &v2 ./output:/output     # Shared mount for generated output
    stop_signal: SIGKILL
    tty: true
    deploy:
      resources:
        reservations:
          devices:
              - driver: nvidia
                device_ids: ['0'] # Use specific GPU ID '0' by default
                capabilities: [compute, utility]
    restart: unless-stopped
    networks:
      - marketmind_net

# --- Project Name ---
name: marketmind-ai

# --- Define Named Network --
networks:
  marketmind_net:
    driver: bridge

# --- Define Named Volumes ---
volumes:
  mongo_data:                  # Volume for MongoDB persistent data
  ollama_data:                 # Volume for Ollama downloaded models
  xtts_models:                 # Volume for XTTS downloaded base models (NOTE: This volume seems unused based on service definitions)

# --- Service Definitions ---
services:

  # --- Flask Application Service ---
  flask_app:
    build: ./Flask_app
    container_name: flask_frontend
    ports:
      - "5003:5000"
    environment:
      - MONGO_URL=mongodb://mongo:27017/marketmind_db
      - IMAGE_API_URL=http://auto:7860
      - OLLAMA_ENDPOINT=http://ollama:11434
      - XTTS_API_URL=http://xtts-service:8020
      - OLLAMA_MODEL=llama3
      - FLASK_SECRET_KEY=CHANGE_THIS_TO_A_VERY_SECURE_RANDOM_STRING_NOW
      - FLASK_ENV=development
    volumes:
      - ./Flask_app:/app
    networks:
      - marketmind_net
    depends_on:
      mongo:
        condition: service_healthy
      ollama:
        condition: service_started
      auto:
        condition: service_started
      xtts-service:
        condition: service_started
    restart: unless-stopped

  # --- AUTOMATIC1111 GPU Service (DEFAULT IMAGE GENERATION) ---
  auto: &automatic
    <<: *base_service
    container_name: automatic1111_gpu
    ports:
      - "${WEBUI_PORT:-7860}:7860"
    image: sha256:a6c3d38d394d926b0861c918d4bb5ecffddf6cb026d97c838837b7dffe02efe4
    environment:
      - CLI_ARGS=--allow-code --medvram --xformers --enable-insecure-extension-access --api --listen
    # Networks inherited from base_service

  # --- AUTOMATIC1111 CPU Service (ALTERNATIVE) ---
  auto-cpu:
    <<: *automatic
    container_name: automatic1111_cpu
    ports:
      - "${WEBUI_PORT:-7860}:7860"
    profiles: ["auto-cpu"]       # Keep Profile - Run explicitly
    deploy: {} # Override deploy to remove GPU allocation
    environment:
      - CLI_ARGS=--no-half --precision full --use-cpu all --skip-torch-cuda-test --allow-code --enable-insecure-extension-access --api --listen
    networks:
      - marketmind_net

  # --- ComfyUI GPU Service (ALTERNATIVE) ---
  comfy: &comfy
    <<: *base_service
    container_name: comfyui_gpu
    ports:
      - "${COMFY_PORT:-8188}:8188"
    profiles: ["comfy"]          # Keep Profile - Run explicitly
    build: ./services/comfy/    # Assuming this build context exists
    image: sd-comfy:7           # Assuming this image exists or build works
    environment:
      - CLI_ARGS= --listen      # Example args, adjust as needed
    # Networks and deploy (GPU) inherited from base_service

  # --- ComfyUI CPU Service (ALTERNATIVE) ---
  comfy-cpu:
    <<: *comfy
    container_name: comfyui_cpu
    ports:
      - "${COMFY_PORT:-8188}:8188"
    profiles: ["comfy-cpu"]      # Keep Profile - Run explicitly
    deploy: {} # Override deploy to remove GPU allocation
    environment:
      - CLI_ARGS=--cpu
    networks:
      - marketmind_net

  # --- MongoDB Service ---
  mongo:
    image: mongo:latest
    container_name: mongo
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
    networks:
      - marketmind_net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # --- Ollama Service ---
  ollama:
    image: ollama/ollama:latest
    container_name: ollama_service
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama # Maps named volume to Ollama's internal storage
    networks:
      - marketmind_net
    deploy: # Use GPU
      resources:
        reservations:
          devices:
              - driver: nvidia
                device_ids: ['0']
                capabilities: [gpu]
    restart: unless-stopped

  # --- XTTS Text-to-Speech Service ---
  xtts-service:
    image: daswer123/xtts-api-server:latest
    container_name: xtts_service
    ports:
      - "8020:8020"
    volumes:
      # --- IMPORTANT: Ensure these host paths contain the required files BEFORE starting! ---
      - ./data/models/xtts:/app/models  # XTTS base model files must be here
      - ./xtts/speakers:/app/xtts/actors       # Your speaker .wav files must be here
      - ./xtts/output_audio:/app/output_audio # Where generated audio will be saved inside container
    networks:
      - marketmind_net
    command: [
        "python3", "-m", "xtts_api_server",
        "-v", "v2.0.3",
        "--port", "8020",
        "--host", "0.0.0.0",
        "--device", "cuda:0",
        "--model-folder", "/app/models",
        "--speaker-folder", "/app/speakers",
        "--output", "/app/output_audio",
        "--use-cache",
        "--lowvram"
      ]
    deploy:
      resources:
        reservations:
          devices:
              - driver: nvidia
                device_ids: ['0']
                capabilities: [gpu]
    restart: unless-stopped
    # --- REMOVED depends_on block for 'download' ---